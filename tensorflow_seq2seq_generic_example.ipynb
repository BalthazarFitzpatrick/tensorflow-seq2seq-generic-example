{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# math stuff\n",
    "import numpy as np\n",
    "\n",
    "# tensorflow all the things\n",
    "import tensorflow as tf\n",
    "\n",
    "# suppress numpy scientific e-notation for better readability\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.1\n"
     ]
    }
   ],
   "source": [
    "# tensorflow version\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0.     1.     2.     3.]\n",
      " [    4.     5.     6.     7.]\n",
      " [    8.     9.    10.    11.]\n",
      " ..., \n",
      " [ 3988.  3989.  3990.  3991.]\n",
      " [ 3992.  3993.  3994.  3995.]\n",
      " [ 3996.  3997.  3998.  3999.]]\n"
     ]
    }
   ],
   "source": [
    "# create dummy data similar to what my database query returns (several features over time)\n",
    "smooth_data = np.float64(np.arange(4000).reshape((1000, 4)))\n",
    "print(smooth_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set generator input, parameters, tensorflow sos, eos and pad tokens\n",
    "\n",
    "# create variables and assign values\n",
    "sequence = smooth_data\n",
    "observation_length = 4 # data the network will see\n",
    "prediction_length = 2 # data the network will learn to predict\n",
    "stride = 2 # number of time steps the window will incrementally slide for each batch \n",
    "total_length = observation_length + prediction_length # total length of observation and prediction array\n",
    "\n",
    "# define generator function\n",
    "def gen_seq():\n",
    "    \n",
    "    # compute number of batches to emit\n",
    "    num_of_batches = round(((len(sequence) - total_length) / stride))\n",
    "    \n",
    "    # transform and emit data in batches\n",
    "    for i in range(0, num_of_batches * stride, stride):\n",
    "        result = np.array(sequence[i:i + total_length])\n",
    "        \n",
    "        # flip array upside down as data is ordered by date desc\n",
    "        result_flipped = np.flipud(result)\n",
    "        \n",
    "        # preparing encoder inputs, adding end of sequence token\n",
    "        enc_inp = result_flipped[0:observation_length]\n",
    "        \n",
    "        # preparing decoder inputs, adding go and end of sequence tokens\n",
    "        dec_inp = result_flipped[observation_length:total_length]\n",
    "        dec_inp = dec_inp[:,0].reshape((prediction_length, 1))\n",
    "        \n",
    "        # preparing target values, adding end of sequence tokens\n",
    "        dec_exp_out = result_flipped[observation_length:total_length]\n",
    "        dec_exp_out = dec_exp_out[:,0].reshape((prediction_length, 1))\n",
    "        \n",
    "        # yield results\n",
    "        yield enc_inp, dec_inp, dec_exp_out\n",
    "\n",
    "gen = gen_seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 20.  21.  22.  23.]\n",
      " [ 16.  17.  18.  19.]\n",
      " [ 12.  13.  14.  15.]\n",
      " [  8.   9.  10.  11.]]\n",
      "\n",
      "[[ 4.]\n",
      " [ 0.]]\n",
      "\n",
      "[[ 4.]\n",
      " [ 0.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "enc_inp, dec_inp, dec_exp_out = next(gen)\n",
    "print(enc_inp)\n",
    "print(\"\")\n",
    "print(dec_inp)\n",
    "print(\"\")\n",
    "print(dec_exp_out)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder input [max_time, batch_size, num_features]\n",
      "Tensor(\"transpose:0\", shape=(4, 5, 4), dtype=float32)\n",
      "\n",
      "decoder input [max_time, batch_size, num_features]\n",
      "Tensor(\"transpose_1:0\", shape=(2, 5, 1), dtype=float32)\n",
      "\n",
      "decoder expected output [max_time, batch_size, num_features]\n",
      "Tensor(\"transpose_2:0\", shape=(2, 5, 1), dtype=float32)\n",
      "\n",
      "encoder output [max_time, batch_size, num_units]\n",
      "Tensor(\"rnn/TensorArrayStack/TensorArrayGatherV3:0\", shape=(4, 5, 3), dtype=float32)\n",
      "\n",
      "encoder state [batch_size, num_units]\n",
      "(LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_2:0' shape=(5, 3) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_3:0' shape=(5, 3) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_4:0' shape=(5, 3) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_5:0' shape=(5, 3) dtype=float32>))\n",
      "\n",
      "final state [batch_size, num_units]\n",
      "(LSTMStateTuple(c=<tf.Tensor 'decoder/while/Exit_3:0' shape=(5, 3) dtype=float32>, h=<tf.Tensor 'decoder/while/Exit_4:0' shape=(5, 3) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'decoder/while/Exit_5:0' shape=(5, 3) dtype=float32>, h=<tf.Tensor 'decoder/while/Exit_6:0' shape=(5, 3) dtype=float32>))\n",
      "\n",
      "logits [max_time, batch_size, num_units]\n",
      "[[[-0.05484364 -0.07058997  0.02749842]\n",
      "  [-0.07178361 -0.0871575   0.05028066]\n",
      "  [-0.07300289 -0.08114677  0.05918329]\n",
      "  [-0.07279234 -0.07729323  0.06338283]\n",
      "  [-0.07243454 -0.07548095  0.06542399]]\n",
      "\n",
      " [[-0.06554358 -0.08957178  0.03686916]\n",
      "  [-0.09201687 -0.14681944  0.07398522]\n",
      "  [-0.09496185 -0.1310636   0.09222451]\n",
      "  [-0.09562492 -0.12142723  0.10073002]\n",
      "  [-0.09553139 -0.11719818  0.10449956]]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# batch-major vs time-major tensors \n",
    "# time-major is computationally less expensive\n",
    "time_major = True\n",
    "\n",
    "# number of features going into the encoder\n",
    "dim_width_enc_inp = len(smooth_data[1])\n",
    "\n",
    "# number of features going into the decoder that match the target sequence\n",
    "dim_width_dec_inp = 1\n",
    "dim_width_dec_exp_out = dim_width_dec_inp\n",
    "\n",
    "# number of batches used in each iteration for parallel processing\n",
    "batch_size = 5\n",
    "\n",
    "# length of input and output\n",
    "# [batch_size] vector for time-major = [5, 4, 6] for three sequences with lengths 5, 4 and 6\n",
    "seq_length_inp = tf.fill([batch_size], observation_length)\n",
    "seq_length_out = tf.fill([batch_size], prediction_length)\n",
    "\n",
    "# create tensorflow placeholder\n",
    "enc_inp = tf.placeholder(\n",
    "    tf.float32, \n",
    "    shape=(observation_length, batch_size, dim_width_enc_inp), \n",
    "    name=\"encoder_input\")\n",
    "dec_inp = tf.placeholder(\n",
    "    tf.float32, \n",
    "    shape=(prediction_length, batch_size, dim_width_dec_inp), \n",
    "    name=\"decoder_input\")\n",
    "dec_exp_out = tf.placeholder(\n",
    "    tf.float32, \n",
    "    shape=(prediction_length, batch_size, dim_width_dec_exp_out), \n",
    "    name=\"target_sequence\")\n",
    "\n",
    "# create tensorflow dataset from generator\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    gen_seq,\n",
    "    (tf.float32, \n",
    "     tf.float32,\n",
    "     tf.float32),\n",
    "    (tf.TensorShape([observation_length, dim_width_enc_inp]), \n",
    "     tf.TensorShape([prediction_length, dim_width_dec_inp]),\n",
    "     tf.TensorShape([prediction_length, dim_width_dec_exp_out]))\n",
    "    )\n",
    "\n",
    "# prefetch 'batch_size' generator outputs\n",
    "prefetched = dataset.prefetch(batch_size)\n",
    "\n",
    "# batch prefetched together\n",
    "batches = prefetched.batch(batch_size)\n",
    "\n",
    "# create one shot iterator\n",
    "enc_inp, dec_inp, dec_exp_out = batches.make_one_shot_iterator().get_next()\n",
    "\n",
    "# convert input to tensors and transpose for time major\n",
    "enc_inp, dec_inp, dec_exp_out = sess.run([enc_inp, dec_inp, dec_exp_out])\n",
    "\n",
    "enc_inp = tf.convert_to_tensor(enc_inp, dtype=tf.float32)\n",
    "enc_inp = tf.transpose(enc_inp, perm = [1, 0, 2])\n",
    "dec_inp = tf.convert_to_tensor(dec_inp, dtype=tf.float32)\n",
    "dec_inp = tf.transpose(dec_inp, perm = [1, 0, 2])\n",
    "dec_exp_out = tf.convert_to_tensor(dec_exp_out, dtype=tf.float32)\n",
    "dec_exp_out = tf.transpose(dec_exp_out, perm = [1, 0, 2])\n",
    "\n",
    "# defining layers and number of units for basic lstm cells\n",
    "enc_layers = 2\n",
    "enc_num_units = 3\n",
    "dec_layers = enc_layers\n",
    "dec_num_units = enc_num_units\n",
    "\n",
    "enc_cells = []\n",
    "for i in range(enc_layers):\n",
    "    with tf.variable_scope(\"rnn_enc\") as rnn_enc:\n",
    "        enc_cells.append(tf.nn.rnn_cell.BasicLSTMCell(enc_num_units))\n",
    "enc_cell = tf.nn.rnn_cell.MultiRNNCell(enc_cells)\n",
    "\n",
    "dec_cells = []\n",
    "for i in range(dec_layers):\n",
    "    with tf.variable_scope(\"rnn_dec\") as rnn_dec:\n",
    "        dec_cells.append(tf.nn.rnn_cell.BasicLSTMCell(dec_num_units))\n",
    "dec_cell = tf.nn.rnn_cell.MultiRNNCell(dec_cells)\n",
    "\n",
    "# encoder\n",
    "enc_out, enc_state = tf.nn.dynamic_rnn(\n",
    "    enc_cell, \n",
    "    enc_inp,\n",
    "    dtype = tf.float32,\n",
    "    sequence_length = seq_length_inp,\n",
    "    time_major = time_major)\n",
    "\n",
    "# helper\n",
    "helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "    dec_inp, \n",
    "    seq_length_out, \n",
    "    time_major = time_major)\n",
    "\n",
    "# decoder\n",
    "decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "    dec_cell, \n",
    "    helper, \n",
    "    enc_state)\n",
    "\n",
    "# dynamic decoding\n",
    "dec_out, dec_state, dec_out_seq_length = tf.contrib.seq2seq.dynamic_decode(decoder, output_time_major = time_major)\n",
    "\n",
    "# create variables for weights and biases\n",
    "weights = tf.Variable(tf.random_normal([dim_width_dec_inp, enc_num_units]))\n",
    "biases = tf.Variable(tf.random_normal([enc_num_units], mean=1.0))\n",
    "\n",
    "# initialize global variables / check for uninitialized variables\n",
    "sess.run(tf.global_variables_initializer())\n",
    "#print(sess.run(tf.report_uninitialized_variables()))\n",
    "\n",
    "# extract logits from decoder output\n",
    "logits = dec_out.rnn_output\n",
    "\n",
    "print(\"encoder input [max_time, batch_size, num_features]\")\n",
    "print(enc_inp)\n",
    "print(\"\")\n",
    "print(\"decoder input [max_time, batch_size, num_features]\")\n",
    "print(dec_inp)\n",
    "print(\"\")\n",
    "print(\"decoder expected output [max_time, batch_size, num_features]\")\n",
    "print(dec_exp_out)\n",
    "print(\"\")\n",
    "print(\"encoder output [max_time, batch_size, num_units]\")\n",
    "print(enc_out)\n",
    "print(\"\")\n",
    "print(\"encoder state [batch_size, num_units]\")\n",
    "print(enc_state)\n",
    "print(\"\")\n",
    "print(\"final state [batch_size, num_units]\")\n",
    "print(dec_state)\n",
    "print(\"\")\n",
    "print(\"logits [max_time, batch_size, num_units]\")\n",
    "print(logits.eval())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
